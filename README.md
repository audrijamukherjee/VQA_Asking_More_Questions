# VQA_Asking_More_Questions

VQA involves answering a question for a given image. These questions are generated by humans on Amazon turk. This ends up being time consuming and expensive leading to further frustration. 

To simplify this process, we use automatic generated question. Instead of human, we use a bot to ask questions. 

Our question generation model is inspired from an image captioning model named Neuraltalk2. We use a CNN to extract image features followed by LSTM to generate the words of these questions. 

These questions tend to be human-like and visually grounded.

We trained an answering bot on [VQA 2.0](http://visualqa.org/) with only human questions and compare it against another bot trained on additional questions from our model. We observe improvements in accuracy across all categories. 
